# app.py

import streamlit as st
import torch
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_mll
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition.analytic import ExpectedImprovement
from botorch.optim import optimize_acqf

# -------------------- ğŸŒŸ Streamlit UI --------------------
st.title("ğŸ”¬ Slurry ì¡°ì„± ì¶”ì²œ (Bayesian Optimization ê¸°ë°˜)")
st.write("ìŠ¬ëŸ¬ë¦¬ ì¡°ì„±ì— ë”°ë¥¸ Yield Stress ê°’ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•œ ì¶”ì²œ ì¡°ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")

# -------------------- ğŸ“‚ ë°ì´í„° ë¡œë”© --------------------
try:
    df = pd.read_csv("slurry_data.csv")
except FileNotFoundError:
    st.error("âŒ 'slurry_data.csv' íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

x_cols = ["graphite_g", "carbon_black_g", "CMC_g", "solvent_g"]
y_cols = ["yield_stress"]

# -------------------- âš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬ --------------------
X_raw = df[x_cols].values
Y_raw = df[y_cols].values

x_scaler = MinMaxScaler()
X_scaled = x_scaler.fit_transform(X_raw)

train_x = torch.tensor(X_scaled, dtype=torch.double)
train_y = torch.tensor(Y_raw, dtype=torch.double).unsqueeze(-1)  # (N, 1)

# -------------------- ğŸ“ˆ GP ëª¨ë¸ í•™ìŠµ --------------------
if st.button("ğŸ“Œ ì¶”ì²œ ì¡°ì„± ê³„ì‚°í•˜ê¸°"):

    try:
        model = SingleTaskGP(train_x, train_y)
        mll = ExactMarginalLogLikelihood(model.likelihood, model)
        fit_gpytorch_mll(mll)

        # -------------------- ğŸ¯ Acquisition Function --------------------
        best_y = train_y.max()
        acq_fn = ExpectedImprovement(model=model, best_f=best_y, maximize=True)

        bounds = torch.stack([
            torch.zeros(train_x.shape[1], dtype=torch.double),
            torch.ones(train_x.shape[1], dtype=torch.double)
        ])

        # -------------------- ğŸ” ìµœì  ì¡°ì„± íƒìƒ‰ --------------------
        candidate_scaled, _ = optimize_acqf(
            acq_function=acq_fn,
            bounds=bounds,
            q=1,
            num_restarts=5,
            raw_samples=20,
        )

        candidate_np = candidate_scaled.detach().numpy()
        candidate_original = x_scaler.inverse_transform(candidate_np)

        # -------------------- âœ… ê²°ê³¼ ì¶œë ¥ --------------------
        st.success("âœ… ì¶”ì²œëœ ìŠ¬ëŸ¬ë¦¬ ì¡°ì„± (g ê¸°ì¤€):")
        for i, name in enumerate(x_cols):
            st.write(f"- **{name}**: {candidate_original[0][i]:.4f} g")

    except Exception as e:
        st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
